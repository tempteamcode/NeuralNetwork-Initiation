Microsoft Windows [version 10.0.14393]
(c) 2016 Microsoft Corporation. Tous droits réservés.

C:\Users\nmesnard>cd "C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1"

C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>C:\Anaconda2\Scripts\activate base

(base) C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>python lenet_modified_bis.py
Traceback (most recent call last):
  File "lenet_modified_bis.py", line 118, in <module>
    y = model(data)
  File "C:\Anaconda2\lib\site-packages\torch\nn\modules\module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "lenet_modified_bis.py", line 48, in forward
    x = F.max_pool2d(x, 4, 0)
  File "C:\Anaconda2\lib\site-packages\torch\_jit_internal.py", line 133, in fn
    return if_false(*args, **kwargs)
  File "C:\Anaconda2\lib\site-packages\torch\nn\functional.py", line 494, in _max_pool2d
    input, kernel_size, stride, padding, dilation, ceil_mode)
RuntimeError: invalid argument 8: stride should be greater than zero, but got dH: 0 dW: 0 at C:/w/1/s/tmp_conda_3.6_041836/conda/conda-bld/pytorch_1556684464974/work/aten/src\THCUNN/generic/SpatialDilatedMaxPooling.cu:18

(base) C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>python lenet_modified_bis.py
Traceback (most recent call last):
  File "lenet_modified_bis.py", line 118, in <module>
    y = model(data)
  File "C:\Anaconda2\lib\site-packages\torch\nn\modules\module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "lenet_modified_bis.py", line 51, in forward
    x = x.view(-1, 23*23*5)
RuntimeError: shape '[-1, 2645]' is invalid for input of size 8100000

(base) C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>python lenet_modified_bis.py
Epoch: 1 batch:     1 train-loss: 0.218 train-err: 50.889 100 valid-loss: 12.283 valid-err: 47.529 100
Epoch: 1 batch:    21 train-loss: 12.834 train-err: 45.067  99
Epoch: 1 batch:    41 train-loss: 12.105 train-err: 43.809  99
Epoch: 1 batch:    61 train-loss: 12.230 train-err: 44.262  99
Epoch: 2 batch:     1 train-loss: 2.434 train-err: 44.044  99 valid-loss: 11.965 valid-err: 43.302  99
Epoch: 2 batch:    21 train-loss: 12.109 train-err: 43.822  99
Epoch: 2 batch:    41 train-loss: 12.194 train-err: 44.133  99
Epoch: 2 batch:    61 train-loss: 12.261 train-err: 44.373  99
Epoch: 3 batch:     1 train-loss: 2.487 train-err: 45.000  99 valid-loss: 11.965 valid-err: 43.302  99
Epoch: 3 batch:    21 train-loss: 12.159 train-err: 44.004  99
Epoch: 3 batch:    41 train-loss: 12.305 train-err: 44.533  99
Epoch: 3 batch:    61 train-loss: 12.094 train-err: 43.769  99
Epoch: 4 batch:     1 train-loss: 2.450 train-err: 44.333  99 valid-loss: 11.965 valid-err: 43.302  99
Epoch: 4 batch:    21 train-loss: 12.242 train-err: 44.307  99
Traceback (most recent call last):
  File "lenet_modified_bis.py", line 127, in <module>
    running_correct_all += sum(row.sum().item() == 9 for row in (predicted == labels))
  File "lenet_modified_bis.py", line 127, in <genexpr>
    running_correct_all += sum(row.sum().item() == 9 for row in (predicted == labels))
KeyboardInterrupt

(base) C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>python lenet_modified_bis.py
Traceback (most recent call last):
  File "lenet_modified_bis.py", line 118, in <module>
    y = model(data)
  File "C:\Anaconda2\lib\site-packages\torch\nn\modules\module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "lenet_modified_bis.py", line 49, in forward
    x = F.relu(self.conv2(x))
  File "C:\Anaconda2\lib\site-packages\torch\nn\modules\module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "C:\Anaconda2\lib\site-packages\torch\nn\modules\conv.py", line 338, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size 8 3 3 3, expected input[250, 6, 94, 94] to have 3 channels, but got 6 channels instead

(base) C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>python lenet_modified_bis.py
Traceback (most recent call last):
  File "lenet_modified_bis.py", line 118, in <module>
    y = model(data)
  File "C:\Anaconda2\lib\site-packages\torch\nn\modules\module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "lenet_modified_bis.py", line 51, in forward
    x = x.view(BATCHSIZE, 8100000//BATCHSIZE)
RuntimeError: shape '[250, 32400]' is invalid for input of size 16200000

(base) C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>python lenet_modified_bis.py
Epoch: 1 batch:     1 train-loss: 0.069 train-err: 53.689 100 valid-loss: 11.982 valid-err: 41.333 100
Epoch: 1 batch:    21 train-loss: 13.704 train-err: 48.756 100
Epoch: 1 batch:    41 train-loss: 14.174 train-err: 51.298 100
Epoch: 1 batch:    61 train-loss: 14.258 train-err: 51.600 100
Epoch: 2 batch:     1 train-loss: 2.836 train-err: 51.311 100 valid-loss: 14.361 valid-err: 51.973 100
Epoch: 2 batch:    21 train-loss: 14.281 train-err: 51.684 100
Epoch: 2 batch:    41 train-loss: 14.191 train-err: 51.360 100
Traceback (most recent call last):
  File "lenet_modified_bis.py", line 113, in <module>
    for batch_idx, (data, labels, _) in enumerate(train_loader):
  File "C:\Anaconda2\lib\site-packages\torch\utils\data\dataloader.py", line 560, in __next__
    batch = self.collate_fn([self.dataset[i] for i in indices])
  File "C:\Anaconda2\lib\site-packages\torch\utils\data\dataloader.py", line 560, in <listcomp>
    batch = self.collate_fn([self.dataset[i] for i in indices])
  File "C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1\dataset_det.py", line 27, in __getitem__
    img = Image.open("%s/img_%05d.jpg"%(self.dir,index_file))
  File "C:\Anaconda2\lib\site-packages\PIL\Image.py", line 2766, in open
    fp = builtins.open(filename, "rb")
KeyboardInterrupt

(base) C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>python lenet_modified_bis.py
Traceback (most recent call last):
  File "lenet_modified_bis.py", line 118, in <module>
    y = model(data)
  File "C:\Anaconda2\lib\site-packages\torch\nn\modules\module.py", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File "lenet_modified_bis.py", line 51, in forward
    x = x.view(BATCHSIZE, 16200000//BATCHSIZE)
RuntimeError: shape '[250, 64800]' is invalid for input of size 75000

(base) C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>python lenet_modified_bis.py
Epoch: 1 batch:     1 train-loss: 0.055 train-err: 52.311 100 valid-loss: 0.805 valid-err: 38.296 100
Epoch: 1 batch:    21 train-loss: 0.672 train-err: 36.487 100
Epoch: 1 batch:    41 train-loss: 0.640 train-err: 33.318 100
Epoch: 1 batch:    61 train-loss: 0.625 train-err: 32.084 100
Epoch: 2 batch:     1 train-loss: 0.122 train-err: 31.322 100 valid-loss: 0.608 valid-err: 31.171 100
Epoch: 2 batch:    21 train-loss: 0.599 train-err: 30.693 100
Epoch: 2 batch:    41 train-loss: 0.585 train-err: 30.151 100
Epoch: 2 batch:    61 train-loss: 0.579 train-err: 29.967 100
Epoch: 3 batch:     1 train-loss: 0.114 train-err: 29.189 100 valid-loss: 0.575 valid-err: 29.242 100
Epoch: 3 batch:    21 train-loss: 0.567 train-err: 29.000 100
Epoch: 3 batch:    41 train-loss: 0.555 train-err: 28.542 100
Epoch: 3 batch:    61 train-loss: 0.544 train-err: 28.278 100
Epoch: 4 batch:     1 train-loss: 0.107 train-err: 27.978 100 valid-loss: 0.537 valid-err: 27.976 100
Epoch: 4 batch:    21 train-loss: 0.526 train-err: 27.413 100
Epoch: 4 batch:    41 train-loss: 0.526 train-err: 27.391 100
Epoch: 4 batch:    61 train-loss: 0.518 train-err: 26.927 100
Epoch: 5 batch:     1 train-loss: 0.102 train-err: 26.900 100 valid-loss: 0.519 valid-err: 27.169 100
Epoch: 5 batch:    21 train-loss: 0.508 train-err: 26.016 100
Epoch: 5 batch:    41 train-loss: 0.506 train-err: 26.109 100
Epoch: 5 batch:    61 train-loss: 0.497 train-err: 25.071 100
Epoch: 6 batch:     1 train-loss: 0.098 train-err: 24.033 100 valid-loss: 0.491 valid-err: 24.511  99
Epoch: 6 batch:    21 train-loss: 0.473 train-err: 22.976 100
Epoch: 6 batch:    41 train-loss: 0.457 train-err: 22.558 100
Epoch: 6 batch:    61 train-loss: 0.440 train-err: 21.360 100
Epoch: 7 batch:     1 train-loss: 0.086 train-err: 21.333 100 valid-loss: 0.436 valid-err: 21.500  98
Epoch: 7 batch:    21 train-loss: 0.423 train-err: 20.907 100
Epoch: 7 batch:    41 train-loss: 0.424 train-err: 20.900  99
Epoch: 7 batch:    61 train-loss: 0.421 train-err: 20.842  99
Epoch: 8 batch:     1 train-loss: 0.082 train-err: 20.300  99 valid-loss: 0.424 valid-err: 21.233  98
Epoch: 8 batch:    21 train-loss: 0.412 train-err: 20.227  99
Epoch: 8 batch:    41 train-loss: 0.405 train-err: 19.936  99
Epoch: 8 batch:    61 train-loss: 0.408 train-err: 20.289  99
Epoch: 9 batch:     1 train-loss: 0.082 train-err: 20.456  99 valid-loss: 0.410 valid-err: 20.429  97
Epoch: 9 batch:    21 train-loss: 0.399 train-err: 19.800  99
Epoch: 9 batch:    41 train-loss: 0.396 train-err: 19.720  99
Epoch: 9 batch:    61 train-loss: 0.395 train-err: 19.633  99
Epoch: 10 batch:     1 train-loss: 0.081 train-err: 20.322  99 valid-loss: 0.403 valid-err: 19.798  97
Epoch: 10 batch:    21 train-loss: 0.387 train-err: 19.322  99
Epoch: 10 batch:    41 train-loss: 0.387 train-err: 19.296  99
Epoch: 10 batch:    61 train-loss: 0.390 train-err: 19.353  99
Epoch: 11 batch:     1 train-loss: 0.077 train-err: 18.611  99 valid-loss: 0.395 valid-err: 19.831  97
Epoch: 11 batch:    21 train-loss: 0.385 train-err: 19.038  99
Epoch: 11 batch:    41 train-loss: 0.385 train-err: 19.049  98
Epoch: 11 batch:    61 train-loss: 0.379 train-err: 18.571  98
Epoch: 12 batch:     1 train-loss: 0.075 train-err: 18.544  98 valid-loss: 0.387 valid-err: 18.689  96
Epoch: 12 batch:    21 train-loss: 0.372 train-err: 18.191  98
Epoch: 12 batch:    41 train-loss: 0.364 train-err: 17.767  98
Epoch: 12 batch:    61 train-loss: 0.372 train-err: 18.240  98
Epoch: 13 batch:     1 train-loss: 0.073 train-err: 17.656  98 valid-loss: 0.375 valid-err: 18.687  95
Epoch: 13 batch:    21 train-loss: 0.357 train-err: 17.387  98
Epoch: 13 batch:    41 train-loss: 0.358 train-err: 17.527  98
Epoch: 13 batch:    61 train-loss: 0.353 train-err: 17.102  98
Epoch: 14 batch:     1 train-loss: 0.070 train-err: 16.789  98 valid-loss: 0.366 valid-err: 17.816  95
Epoch: 14 batch:    21 train-loss: 0.346 train-err: 16.993  98
Epoch: 14 batch:    41 train-loss: 0.344 train-err: 16.576  98
Epoch: 14 batch:    61 train-loss: 0.344 train-err: 16.771  97
Epoch: 15 batch:     1 train-loss: 0.070 train-err: 16.922  97 valid-loss: 0.361 valid-err: 17.936  93
Epoch: 15 batch:    21 train-loss: 0.335 train-err: 16.198  97
Epoch: 15 batch:    41 train-loss: 0.340 train-err: 16.589  97
Epoch: 15 batch:    61 train-loss: 0.338 train-err: 16.402  97
Epoch: 16 batch:     1 train-loss: 0.066 train-err: 16.200  97 valid-loss: 0.355 valid-err: 17.609  93
Epoch: 16 batch:    21 train-loss: 0.329 train-err: 16.222  97
Epoch: 16 batch:    41 train-loss: 0.340 train-err: 16.718  97
Epoch: 16 batch:    61 train-loss: 0.333 train-err: 16.136  97
Epoch: 17 batch:     1 train-loss: 0.066 train-err: 16.156  97 valid-loss: 0.349 valid-err: 17.131  92
Epoch: 17 batch:    21 train-loss: 0.326 train-err: 15.836  97
Epoch: 17 batch:    41 train-loss: 0.328 train-err: 16.193  97
Epoch: 17 batch:    61 train-loss: 0.323 train-err: 15.827  96
Epoch: 18 batch:     1 train-loss: 0.064 train-err: 15.133  96 valid-loss: 0.346 valid-err: 16.904  92
Epoch: 18 batch:    21 train-loss: 0.320 train-err: 15.698  96
Epoch: 18 batch:    41 train-loss: 0.321 train-err: 15.976  96
Epoch: 18 batch:    61 train-loss: 0.329 train-err: 16.107  96
Epoch: 19 batch:     1 train-loss: 0.065 train-err: 15.689  96 valid-loss: 0.342 valid-err: 16.827  92
Epoch: 19 batch:    21 train-loss: 0.317 train-err: 15.420  96
Epoch: 19 batch:    41 train-loss: 0.315 train-err: 15.600  96
Epoch: 19 batch:    61 train-loss: 0.315 train-err: 15.520  96
Epoch: 20 batch:     1 train-loss: 0.061 train-err: 14.800  96 valid-loss: 0.336 valid-err: 16.462  91
Epoch: 20 batch:    21 train-loss: 0.315 train-err: 15.309  96
Epoch: 20 batch:    41 train-loss: 0.311 train-err: 15.098  96
Epoch: 20 batch:    61 train-loss: 0.311 train-err: 15.356  95
Epoch: 21 batch:     1 train-loss: 0.063 train-err: 15.389  95 valid-loss: 0.336 valid-err: 16.471  90
Epoch: 21 batch:    21 train-loss: 0.306 train-err: 14.860  95
Epoch: 21 batch:    41 train-loss: 0.309 train-err: 15.149  95
Epoch: 21 batch:    61 train-loss: 0.308 train-err: 15.084  95
Epoch: 22 batch:     1 train-loss: 0.060 train-err: 14.433  95 valid-loss: 0.330 valid-err: 16.124  91
Epoch: 22 batch:    21 train-loss: 0.300 train-err: 14.662  95
Epoch: 22 batch:    41 train-loss: 0.305 train-err: 14.847  95
Epoch: 22 batch:    61 train-loss: 0.302 train-err: 14.624  95
Epoch: 23 batch:     1 train-loss: 0.060 train-err: 14.833  95 valid-loss: 0.326 valid-err: 15.669  89
Epoch: 23 batch:    21 train-loss: 0.298 train-err: 14.464  95
Epoch: 23 batch:    41 train-loss: 0.295 train-err: 14.344  95
Epoch: 23 batch:    61 train-loss: 0.293 train-err: 14.227  94
Epoch: 24 batch:     1 train-loss: 0.058 train-err: 13.944  94 valid-loss: 0.317 valid-err: 14.971  86
Epoch: 24 batch:    21 train-loss: 0.283 train-err: 13.516  94
Epoch: 24 batch:    41 train-loss: 0.289 train-err: 13.953  94
Epoch: 24 batch:    61 train-loss: 0.288 train-err: 13.880  94
Epoch: 25 batch:     1 train-loss: 0.058 train-err: 13.989  94 valid-loss: 0.307 valid-err: 14.376  84
Epoch: 25 batch:    21 train-loss: 0.280 train-err: 13.240  94
Epoch: 25 batch:    41 train-loss: 0.273 train-err: 12.984  94
Epoch: 25 batch:    61 train-loss: 0.280 train-err: 13.244  93
Epoch: 26 batch:     1 train-loss: 0.056 train-err: 13.356  93 valid-loss: 0.305 valid-err: 13.982  82
Epoch: 26 batch:    21 train-loss: 0.268 train-err: 12.640  93
Epoch: 26 batch:    41 train-loss: 0.273 train-err: 12.976  93
Epoch: 26 batch:    61 train-loss: 0.275 train-err: 13.044  93
Epoch: 27 batch:     1 train-loss: 0.055 train-err: 12.733  93 valid-loss: 0.299 valid-err: 13.656  82
Epoch: 27 batch:    21 train-loss: 0.265 train-err: 12.482  92
Epoch: 27 batch:    41 train-loss: 0.268 train-err: 12.682  92
Epoch: 27 batch:    61 train-loss: 0.268 train-err: 12.669  92
Epoch: 28 batch:     1 train-loss: 0.055 train-err: 12.667  92 valid-loss: 0.290 valid-err: 13.222  78
Epoch: 28 batch:    21 train-loss: 0.256 train-err: 12.036  92
Epoch: 28 batch:    41 train-loss: 0.261 train-err: 12.093  92
Epoch: 28 batch:    61 train-loss: 0.260 train-err: 12.193  91
Epoch: 29 batch:     1 train-loss: 0.050 train-err: 11.733  91 valid-loss: 0.285 valid-err: 12.827  76
Epoch: 29 batch:    21 train-loss: 0.250 train-err: 11.716  91
Epoch: 29 batch:    41 train-loss: 0.260 train-err: 12.076  91
Epoch: 29 batch:    61 train-loss: 0.254 train-err: 11.953  91
Epoch: 30 batch:     1 train-loss: 0.051 train-err: 11.889  91 valid-loss: 0.281 valid-err: 12.538  73
Epoch: 30 batch:    21 train-loss: 0.248 train-err: 11.580  91
Epoch: 30 batch:    41 train-loss: 0.244 train-err: 11.104  90
Epoch: 30 batch:    61 train-loss: 0.250 train-err: 11.404  90
Epoch: 31 batch:     1 train-loss: 0.049 train-err: 11.211  90 valid-loss: 0.275 valid-err: 12.113  72
Epoch: 31 batch:    21 train-loss: 0.234 train-err: 10.562  90
Epoch: 31 batch:    41 train-loss: 0.232 train-err: 10.453  90
Epoch: 31 batch:    61 train-loss: 0.228 train-err: 10.122  89
Epoch: 32 batch:     1 train-loss: 0.045 train-err: 10.044  89 valid-loss: 0.258 valid-err: 10.713  66
Epoch: 32 batch:    21 train-loss: 0.215 train-err: 9.360  89
Epoch: 32 batch:    41 train-loss: 0.211 train-err: 9.104  89
Epoch: 32 batch:    61 train-loss: 0.208 train-err: 9.140  88
Epoch: 33 batch:     1 train-loss: 0.043 train-err: 9.222  88 valid-loss: 0.231 valid-err: 9.447  59
Epoch: 33 batch:    21 train-loss: 0.200 train-err: 8.522  88
Epoch: 33 batch:    41 train-loss: 0.198 train-err: 8.400  88
Epoch: 33 batch:    61 train-loss: 0.189 train-err: 7.904  87
Epoch: 34 batch:     1 train-loss: 0.038 train-err: 8.044  87 valid-loss: 0.216 valid-err: 8.587  55
Epoch: 34 batch:    21 train-loss: 0.176 train-err: 7.496  87
Epoch: 34 batch:    41 train-loss: 0.183 train-err: 7.820  87
Epoch: 34 batch:    61 train-loss: 0.181 train-err: 7.720  86
Epoch: 35 batch:     1 train-loss: 0.034 train-err: 7.278  86 valid-loss: 0.198 valid-err: 7.884  52
Epoch: 35 batch:    21 train-loss: 0.163 train-err: 6.969  86
Epoch: 35 batch:    41 train-loss: 0.172 train-err: 7.196  86
Epoch: 35 batch:    61 train-loss: 0.170 train-err: 7.040  85
Epoch: 36 batch:     1 train-loss: 0.032 train-err: 6.422  85 valid-loss: 0.193 valid-err: 7.669  50
Epoch: 36 batch:    21 train-loss: 0.157 train-err: 6.669  85
Epoch: 36 batch:    41 train-loss: 0.158 train-err: 6.496  84
Epoch: 36 batch:    61 train-loss: 0.159 train-err: 6.607  84
Epoch: 37 batch:     1 train-loss: 0.033 train-err: 6.744  84 valid-loss: 0.185 valid-err: 7.338  48
Epoch: 37 batch:    21 train-loss: 0.150 train-err: 6.202  84
Epoch: 37 batch:    41 train-loss: 0.149 train-err: 6.189  83
Epoch: 37 batch:    61 train-loss: 0.151 train-err: 6.218  83
Epoch: 38 batch:     1 train-loss: 0.031 train-err: 6.256  83 valid-loss: 0.175 valid-err: 6.858  45
Epoch: 38 batch:    21 train-loss: 0.141 train-err: 5.724  83
Epoch: 38 batch:    41 train-loss: 0.142 train-err: 5.802  82
Epoch: 38 batch:    61 train-loss: 0.142 train-err: 5.687  82
Epoch: 39 batch:     1 train-loss: 0.029 train-err: 5.900  82 valid-loss: 0.172 valid-err: 6.573  44
Epoch: 39 batch:    21 train-loss: 0.130 train-err: 5.313  81
Epoch: 39 batch:    41 train-loss: 0.138 train-err: 5.509  81
Epoch: 39 batch:    61 train-loss: 0.139 train-err: 5.647  81
Epoch: 40 batch:     1 train-loss: 0.028 train-err: 5.722  81 valid-loss: 0.172 valid-err: 6.856  46
Epoch: 40 batch:    21 train-loss: 0.133 train-err: 5.296  80
Epoch: 40 batch:    41 train-loss: 0.128 train-err: 5.080  80
Epoch: 40 batch:    61 train-loss: 0.130 train-err: 5.100  80
Epoch: 41 batch:     1 train-loss: 0.025 train-err: 5.144  80 valid-loss: 0.163 valid-err: 6.180  41
Epoch: 41 batch:    21 train-loss: 0.120 train-err: 4.698  79
Epoch: 41 batch:    41 train-loss: 0.127 train-err: 5.018  79
Epoch: 41 batch:    61 train-loss: 0.128 train-err: 5.120  78
Epoch: 42 batch:     1 train-loss: 0.025 train-err: 4.911  78 valid-loss: 0.161 valid-err: 6.084  42
Epoch: 42 batch:    21 train-loss: 0.118 train-err: 4.624  78
Epoch: 42 batch:    41 train-loss: 0.115 train-err: 4.533  78
Epoch: 42 batch:    61 train-loss: 0.124 train-err: 4.847  77
Epoch: 43 batch:     1 train-loss: 0.024 train-err: 4.489  77 valid-loss: 0.155 valid-err: 5.796  37
Epoch: 43 batch:    21 train-loss: 0.112 train-err: 4.449  77
Epoch: 43 batch:    41 train-loss: 0.111 train-err: 4.282  77
Epoch: 43 batch:    61 train-loss: 0.117 train-err: 4.573  76
Epoch: 44 batch:     1 train-loss: 0.023 train-err: 4.411  76 valid-loss: 0.156 valid-err: 5.640  36
Epoch: 44 batch:    21 train-loss: 0.105 train-err: 4.024  76
Epoch: 44 batch:    41 train-loss: 0.110 train-err: 4.264  76
Epoch: 44 batch:    61 train-loss: 0.116 train-err: 4.511  75
Epoch: 45 batch:     1 train-loss: 0.022 train-err: 3.967  75 valid-loss: 0.156 valid-err: 5.796  39
Epoch: 45 batch:    21 train-loss: 0.106 train-err: 3.976  75
Epoch: 45 batch:    41 train-loss: 0.106 train-err: 4.000  75
Epoch: 45 batch:    61 train-loss: 0.109 train-err: 4.189  74
Epoch: 46 batch:     1 train-loss: 0.021 train-err: 4.078  74 valid-loss: 0.153 valid-err: 5.573  38
Epoch: 46 batch:    21 train-loss: 0.100 train-err: 3.827  74
Epoch: 46 batch:    41 train-loss: 0.103 train-err: 3.942  74
Epoch: 46 batch:    61 train-loss: 0.104 train-err: 3.951  73
Epoch: 47 batch:     1 train-loss: 0.021 train-err: 3.900  73 valid-loss: 0.155 valid-err: 5.602  37
Epoch: 47 batch:    21 train-loss: 0.098 train-err: 3.738  73
Epoch: 47 batch:    41 train-loss: 0.101 train-err: 3.709  72
Epoch: 47 batch:    61 train-loss: 0.097 train-err: 3.591  72
Epoch: 48 batch:     1 train-loss: 0.020 train-err: 3.744  72 valid-loss: 0.151 valid-err: 5.324  34
Epoch: 48 batch:    21 train-loss: 0.094 train-err: 3.562  72
Epoch: 48 batch:    41 train-loss: 0.097 train-err: 3.620  72
Epoch: 48 batch:    61 train-loss: 0.096 train-err: 3.593  71
Epoch: 49 batch:     1 train-loss: 0.019 train-err: 3.511  71 valid-loss: 0.145 valid-err: 5.116  34
Epoch: 49 batch:    21 train-loss: 0.094 train-err: 3.520  71
Epoch: 49 batch:    41 train-loss: 0.095 train-err: 3.629  71
Epoch: 49 batch:    61 train-loss: 0.090 train-err: 3.340  70
Epoch: 50 batch:     1 train-loss: 0.019 train-err: 3.500  70 valid-loss: 0.144 valid-err: 5.129  33
Epoch: 50 batch:    21 train-loss: 0.085 train-err: 3.169  70
Epoch: 50 batch:    41 train-loss: 0.087 train-err: 3.311  70
Epoch: 50 batch:    61 train-loss: 0.095 train-err: 3.571  69
Epoch: 51 batch:     1 train-loss: 0.018 train-err: 3.489  69 valid-loss: 0.145 valid-err: 5.116  34
Epoch: 51 batch:    21 train-loss: 0.083 train-err: 3.040  69
Epoch: 51 batch:    41 train-loss: 0.087 train-err: 3.258  69
Epoch: 51 batch:    61 train-loss: 0.090 train-err: 3.456  68
Epoch: 52 batch:     1 train-loss: 0.018 train-err: 3.400  68 valid-loss: 0.136 valid-err: 4.707  31
Epoch: 52 batch:    21 train-loss: 0.078 train-err: 2.913  68
Epoch: 52 batch:    41 train-loss: 0.087 train-err: 3.193  68
Epoch: 52 batch:    61 train-loss: 0.084 train-err: 3.118  68
Epoch: 53 batch:     1 train-loss: 0.017 train-err: 3.256  67 valid-loss: 0.139 valid-err: 4.760  31
Epoch: 53 batch:    21 train-loss: 0.076 train-err: 2.847  67
Epoch: 53 batch:    41 train-loss: 0.084 train-err: 3.200  67
Epoch: 53 batch:    61 train-loss: 0.081 train-err: 3.087  67
Epoch: 54 batch:     1 train-loss: 0.016 train-err: 3.000  67 valid-loss: 0.137 valid-err: 4.809  32
Epoch: 54 batch:    21 train-loss: 0.076 train-err: 2.771  66
Epoch: 54 batch:    41 train-loss: 0.078 train-err: 2.904  66
Epoch: 54 batch:    61 train-loss: 0.078 train-err: 2.824  66
Epoch: 55 batch:     1 train-loss: 0.015 train-err: 2.456  66 valid-loss: 0.139 valid-err: 4.664  29
Epoch: 55 batch:    21 train-loss: 0.067 train-err: 2.440  65
Epoch: 55 batch:    41 train-loss: 0.076 train-err: 2.842  65
Epoch: 55 batch:    61 train-loss: 0.082 train-err: 3.131  65
Epoch: 56 batch:     1 train-loss: 0.016 train-err: 2.789  65 valid-loss: 0.138 valid-err: 4.660  31
Epoch: 56 batch:    21 train-loss: 0.075 train-err: 2.727  65
Epoch: 56 batch:    41 train-loss: 0.076 train-err: 2.862  64
Epoch: 56 batch:    61 train-loss: 0.078 train-err: 2.900  64
Epoch: 57 batch:     1 train-loss: 0.015 train-err: 2.711  64 valid-loss: 0.135 valid-err: 4.511  30
Epoch: 57 batch:    21 train-loss: 0.066 train-err: 2.429  64
Epoch: 57 batch:    41 train-loss: 0.070 train-err: 2.584  64
Epoch: 57 batch:    61 train-loss: 0.074 train-err: 2.727  63
Epoch: 58 batch:     1 train-loss: 0.015 train-err: 2.711  63 valid-loss: 0.138 valid-err: 4.669  31
Epoch: 58 batch:    21 train-loss: 0.067 train-err: 2.491  63
Epoch: 58 batch:    41 train-loss: 0.070 train-err: 2.567  63
Epoch: 58 batch:    61 train-loss: 0.073 train-err: 2.691  63
Epoch: 59 batch:     1 train-loss: 0.015 train-err: 2.856  63 valid-loss: 0.143 valid-err: 4.747  30
Epoch: 59 batch:    21 train-loss: 0.068 train-err: 2.516  62
Epoch: 59 batch:    41 train-loss: 0.070 train-err: 2.584  62
Epoch: 59 batch:    61 train-loss: 0.069 train-err: 2.502  62
Epoch: 60 batch:     1 train-loss: 0.014 train-err: 2.656  62 valid-loss: 0.136 valid-err: 4.513  30
Epoch: 60 batch:    21 train-loss: 0.060 train-err: 2.204  62
Epoch: 60 batch:    41 train-loss: 0.063 train-err: 2.284  61
Epoch: 60 batch:    61 train-loss: 0.073 train-err: 2.747  61
Epoch: 61 batch:     1 train-loss: 0.014 train-err: 2.633  61 valid-loss: 0.137 valid-err: 4.476  29
Epoch: 61 batch:    21 train-loss: 0.064 train-err: 2.358  61
Epoch: 61 batch:    41 train-loss: 0.067 train-err: 2.511  61
Epoch: 61 batch:    61 train-loss: 0.066 train-err: 2.429  60
Epoch: 62 batch:     1 train-loss: 0.013 train-err: 2.544  60 valid-loss: 0.139 valid-err: 4.613  31
Epoch: 62 batch:    21 train-loss: 0.059 train-err: 2.209  60
Epoch: 62 batch:    41 train-loss: 0.067 train-err: 2.424  60
Epoch: 62 batch:    61 train-loss: 0.071 train-err: 2.678  60
Epoch: 63 batch:     1 train-loss: 0.014 train-err: 2.844  60 valid-loss: 0.135 valid-err: 4.456  30
Epoch: 63 batch:    21 train-loss: 0.064 train-err: 2.404  59
Epoch: 63 batch:    41 train-loss: 0.061 train-err: 2.298  59
Epoch: 63 batch:    61 train-loss: 0.064 train-err: 2.318  59
Epoch: 64 batch:     1 train-loss: 0.013 train-err: 2.578  59 valid-loss: 0.133 valid-err: 4.260  28
Epoch: 64 batch:    21 train-loss: 0.055 train-err: 2.053  59
Epoch: 64 batch:    41 train-loss: 0.061 train-err: 2.271  59
Epoch: 64 batch:    61 train-loss: 0.060 train-err: 2.182  58
Epoch: 65 batch:     1 train-loss: 0.013 train-err: 2.311  58 valid-loss: 0.133 valid-err: 4.320  28
Epoch: 65 batch:    21 train-loss: 0.054 train-err: 1.991  58
Epoch: 65 batch:    41 train-loss: 0.055 train-err: 2.069  58
Epoch: 65 batch:    61 train-loss: 0.061 train-err: 2.227  58
Epoch: 66 batch:     1 train-loss: 0.012 train-err: 2.100  58 valid-loss: 0.131 valid-err: 4.298  28
Epoch: 66 batch:    21 train-loss: 0.053 train-err: 1.947  57
Epoch: 66 batch:    41 train-loss: 0.058 train-err: 2.118  57
Epoch: 66 batch:    61 train-loss: 0.058 train-err: 2.164  57
Epoch: 67 batch:     1 train-loss: 0.011 train-err: 2.189  57 valid-loss: 0.139 valid-err: 4.358  28
Epoch: 67 batch:    21 train-loss: 0.050 train-err: 1.829  57
Epoch: 67 batch:    41 train-loss: 0.055 train-err: 2.029  57
Epoch: 67 batch:    61 train-loss: 0.064 train-err: 2.320  56
Epoch: 68 batch:     1 train-loss: 0.013 train-err: 2.456  56 valid-loss: 0.135 valid-err: 4.396  30
Epoch: 68 batch:    21 train-loss: 0.052 train-err: 1.862  56
Epoch: 68 batch:    41 train-loss: 0.054 train-err: 1.953  56
Epoch: 68 batch:    61 train-loss: 0.055 train-err: 2.058  56
Epoch: 69 batch:     1 train-loss: 0.010 train-err: 1.800  56 valid-loss: 0.131 valid-err: 4.109  28
Epoch: 69 batch:    21 train-loss: 0.050 train-err: 1.816  56
Epoch: 69 batch:    41 train-loss: 0.052 train-err: 1.931  55
Epoch: 69 batch:    61 train-loss: 0.055 train-err: 2.004  55
Epoch: 70 batch:     1 train-loss: 0.011 train-err: 1.889  55 valid-loss: 0.141 valid-err: 4.364  29
Epoch: 70 batch:    21 train-loss: 0.050 train-err: 1.858  55
Epoch: 70 batch:    41 train-loss: 0.050 train-err: 1.833  55
Epoch: 70 batch:    61 train-loss: 0.053 train-err: 1.962  55
Epoch: 71 batch:     1 train-loss: 0.008 train-err: 1.433  55 valid-loss: 0.133 valid-err: 4.138  27
Epoch: 71 batch:    21 train-loss: 0.047 train-err: 1.758  54
Epoch: 71 batch:    41 train-loss: 0.053 train-err: 1.958  54
Epoch: 71 batch:    61 train-loss: 0.052 train-err: 1.893  54
Epoch: 72 batch:     1 train-loss: 0.010 train-err: 1.733  54 valid-loss: 0.131 valid-err: 4.071  27
Epoch: 72 batch:    21 train-loss: 0.044 train-err: 1.569  54
Epoch: 72 batch:    41 train-loss: 0.049 train-err: 1.809  54
Epoch: 72 batch:    61 train-loss: 0.052 train-err: 1.989  53
Epoch: 73 batch:     1 train-loss: 0.011 train-err: 2.044  53 valid-loss: 0.143 valid-err: 4.489  29
Epoch: 73 batch:    21 train-loss: 0.045 train-err: 1.658  53
Epoch: 73 batch:    41 train-loss: 0.046 train-err: 1.611  53
Epoch: 73 batch:    61 train-loss: 0.053 train-err: 1.964  53
Epoch: 74 batch:     1 train-loss: 0.009 train-err: 1.722  53 valid-loss: 0.137 valid-err: 4.147  27
Epoch: 74 batch:    21 train-loss: 0.045 train-err: 1.616  53
Epoch: 74 batch:    41 train-loss: 0.048 train-err: 1.771  52
Epoch: 74 batch:    61 train-loss: 0.048 train-err: 1.818  52
Epoch: 75 batch:     1 train-loss: 0.009 train-err: 1.722  52 valid-loss: 0.138 valid-err: 4.100  27
Epoch: 75 batch:    21 train-loss: 0.043 train-err: 1.584  52
Epoch: 75 batch:    41 train-loss: 0.043 train-err: 1.509  52
Epoch: 75 batch:    61 train-loss: 0.046 train-err: 1.713  52
Epoch: 76 batch:     1 train-loss: 0.009 train-err: 1.889  52 valid-loss: 0.138 valid-err: 4.153  27
Epoch: 76 batch:    21 train-loss: 0.045 train-err: 1.556  52
Epoch: 76 batch:    41 train-loss: 0.042 train-err: 1.476  51
Epoch: 76 batch:    61 train-loss: 0.047 train-err: 1.756  51
Epoch: 77 batch:     1 train-loss: 0.008 train-err: 1.489  51 valid-loss: 0.142 valid-err: 4.184  27
Epoch: 77 batch:    21 train-loss: 0.040 train-err: 1.473  51
Epoch: 77 batch:    41 train-loss: 0.045 train-err: 1.711  51
Epoch: 77 batch:    61 train-loss: 0.051 train-err: 1.907  51
Epoch: 78 batch:     1 train-loss: 0.009 train-err: 1.567  51 valid-loss: 0.142 valid-err: 4.318  28
Epoch: 78 batch:    21 train-loss: 0.041 train-err: 1.476  51
Epoch: 78 batch:    41 train-loss: 0.042 train-err: 1.560  50
Epoch: 78 batch:    61 train-loss: 0.044 train-err: 1.691  50
Epoch: 79 batch:     1 train-loss: 0.009 train-err: 1.644  50 valid-loss: 0.140 valid-err: 4.156  27
Epoch: 79 batch:    21 train-loss: 0.038 train-err: 1.396  50
Epoch: 79 batch:    41 train-loss: 0.042 train-err: 1.502  50
Epoch: 79 batch:    61 train-loss: 0.043 train-err: 1.544  50
Epoch: 80 batch:     1 train-loss: 0.008 train-err: 1.356  50 valid-loss: 0.143 valid-err: 4.109  27
Epoch: 80 batch:    21 train-loss: 0.038 train-err: 1.296  50
Epoch: 80 batch:    41 train-loss: 0.041 train-err: 1.496  49
Epoch: 80 batch:    61 train-loss: 0.043 train-err: 1.589  49
Epoch: 81 batch:     1 train-loss: 0.008 train-err: 1.378  49 valid-loss: 0.141 valid-err: 4.053  26
Epoch: 81 batch:    21 train-loss: 0.039 train-err: 1.413  49
Epoch: 81 batch:    41 train-loss: 0.039 train-err: 1.389  49
Epoch: 81 batch:    61 train-loss: 0.041 train-err: 1.562  49
Epoch: 82 batch:     1 train-loss: 0.009 train-err: 1.656  49 valid-loss: 0.147 valid-err: 4.189  27
Epoch: 82 batch:    21 train-loss: 0.039 train-err: 1.491  49
Epoch: 82 batch:    41 train-loss: 0.043 train-err: 1.564  48
Epoch: 82 batch:    61 train-loss: 0.043 train-err: 1.611  48
Epoch: 83 batch:     1 train-loss: 0.009 train-err: 1.611  48 valid-loss: 0.146 valid-err: 4.227  27
Epoch: 83 batch:    21 train-loss: 0.036 train-err: 1.367  48
Epoch: 83 batch:    41 train-loss: 0.044 train-err: 1.684  48
Epoch: 83 batch:    61 train-loss: 0.044 train-err: 1.638  48
Epoch: 84 batch:     1 train-loss: 0.008 train-err: 1.556  48 valid-loss: 0.148 valid-err: 4.209  28
Epoch: 84 batch:    21 train-loss: 0.037 train-err: 1.336  48
Epoch: 84 batch:    41 train-loss: 0.037 train-err: 1.342  48
Epoch: 84 batch:    61 train-loss: 0.040 train-err: 1.507  47
Epoch: 85 batch:     1 train-loss: 0.008 train-err: 1.589  47 valid-loss: 0.147 valid-err: 4.196  28
Epoch: 85 batch:    21 train-loss: 0.035 train-err: 1.258  47
Epoch: 85 batch:    41 train-loss: 0.036 train-err: 1.331  47
Epoch: 85 batch:    61 train-loss: 0.042 train-err: 1.560  47
Epoch: 86 batch:     1 train-loss: 0.009 train-err: 1.667  47 valid-loss: 0.163 valid-err: 4.518  28
Epoch: 86 batch:    21 train-loss: 0.037 train-err: 1.324  47
Epoch: 86 batch:    41 train-loss: 0.038 train-err: 1.349  47
Epoch: 86 batch:    61 train-loss: 0.040 train-err: 1.511  47
Epoch: 87 batch:     1 train-loss: 0.008 train-err: 1.500  47 valid-loss: 0.146 valid-err: 4.167  27
Epoch: 87 batch:    21 train-loss: 0.031 train-err: 1.084  46
Epoch: 87 batch:    41 train-loss: 0.036 train-err: 1.289  46
Epoch: 87 batch:    61 train-loss: 0.037 train-err: 1.393  46
Epoch: 88 batch:     1 train-loss: 0.006 train-err: 1.033  46 valid-loss: 0.156 valid-err: 4.216  28
Epoch: 88 batch:    21 train-loss: 0.031 train-err: 1.064  46
Epoch: 88 batch:    41 train-loss: 0.037 train-err: 1.338  46
Epoch: 88 batch:    61 train-loss: 0.039 train-err: 1.478  46
Epoch: 89 batch:     1 train-loss: 0.008 train-err: 1.578  46 valid-loss: 0.150 valid-err: 4.124  26
Epoch: 89 batch:    21 train-loss: 0.037 train-err: 1.398  46
Epoch: 89 batch:    41 train-loss: 0.037 train-err: 1.384  45
Epoch: 89 batch:    61 train-loss: 0.033 train-err: 1.156  45
Epoch: 90 batch:     1 train-loss: 0.007 train-err: 1.511  45 valid-loss: 0.151 valid-err: 4.058  26
Epoch: 90 batch:    21 train-loss: 0.029 train-err: 0.998  45
Epoch: 90 batch:    41 train-loss: 0.032 train-err: 1.140  45
Epoch: 90 batch:    61 train-loss: 0.034 train-err: 1.231  45
Epoch: 91 batch:     1 train-loss: 0.006 train-err: 1.078  45 valid-loss: 0.156 valid-err: 4.191  27
Epoch: 91 batch:    21 train-loss: 0.029 train-err: 1.000  45
Epoch: 91 batch:    41 train-loss: 0.032 train-err: 1.127  45
Epoch: 91 batch:    61 train-loss: 0.034 train-err: 1.224  45
Epoch: 92 batch:     1 train-loss: 0.006 train-err: 1.144  45 valid-loss: 0.151 valid-err: 4.078  25
Epoch: 92 batch:    21 train-loss: 0.028 train-err: 1.013  44
Epoch: 92 batch:    41 train-loss: 0.036 train-err: 1.260  44
Epoch: 92 batch:    61 train-loss: 0.039 train-err: 1.447  44
Epoch: 93 batch:     1 train-loss: 0.009 train-err: 1.633  44 valid-loss: 0.158 valid-err: 4.333  28
Epoch: 93 batch:    21 train-loss: 0.036 train-err: 1.320  44
Epoch: 93 batch:    41 train-loss: 0.034 train-err: 1.218  44
Epoch: 93 batch:    61 train-loss: 0.040 train-err: 1.482  44
Epoch: 94 batch:     1 train-loss: 0.007 train-err: 1.167  44 valid-loss: 0.155 valid-err: 4.189  27
Epoch: 94 batch:    21 train-loss: 0.034 train-err: 1.240  44
Epoch: 94 batch:    41 train-loss: 0.033 train-err: 1.184  44
Epoch: 94 batch:    61 train-loss: 0.036 train-err: 1.360  43
Epoch: 95 batch:     1 train-loss: 0.007 train-err: 1.289  43 valid-loss: 0.161 valid-err: 4.196  27
Epoch: 95 batch:    21 train-loss: 0.033 train-err: 1.200  43
Epoch: 95 batch:    41 train-loss: 0.049 train-err: 1.747  43
Epoch: 95 batch:    61 train-loss: 0.036 train-err: 1.311  43
Epoch: 96 batch:     1 train-loss: 0.007 train-err: 1.311  43 valid-loss: 0.149 valid-err: 4.042  26
Epoch: 96 batch:    21 train-loss: 0.029 train-err: 1.040  43
Epoch: 96 batch:    41 train-loss: 0.028 train-err: 1.018  43
Epoch: 96 batch:    61 train-loss: 0.032 train-err: 1.160  43
Epoch: 97 batch:     1 train-loss: 0.006 train-err: 1.078  43 valid-loss: 0.159 valid-err: 4.024  26
Epoch: 97 batch:    21 train-loss: 0.027 train-err: 0.947  43
Epoch: 97 batch:    41 train-loss: 0.029 train-err: 0.998  42
Epoch: 97 batch:    61 train-loss: 0.032 train-err: 1.233  42
Epoch: 98 batch:     1 train-loss: 0.006 train-err: 1.189  42 valid-loss: 0.162 valid-err: 4.213  27
Epoch: 98 batch:    21 train-loss: 0.028 train-err: 1.011  42
Epoch: 98 batch:    41 train-loss: 0.029 train-err: 1.000  42
Epoch: 98 batch:    61 train-loss: 0.031 train-err: 1.149  42
Epoch: 99 batch:     1 train-loss: 0.007 train-err: 1.367  42 valid-loss: 0.164 valid-err: 4.269  28
Epoch: 99 batch:    21 train-loss: 0.027 train-err: 0.967  42
Epoch: 99 batch:    41 train-loss: 0.030 train-err: 1.138  42
Epoch: 99 batch:    61 train-loss: 0.030 train-err: 1.091  42
Epoch: 100 batch:     1 train-loss: 0.007 train-err: 1.300  42 valid-loss: 0.159 valid-err: 4.087  26
Epoch: 100 batch:    21 train-loss: 0.026 train-err: 0.931  42
Epoch: 100 batch:    41 train-loss: 0.030 train-err: 1.067  41
Epoch: 100 batch:    61 train-loss: 0.031 train-err: 1.133  41

(base) C:\Temp\ttcgit\NeuralNetwork-Initiation\Exercise 1>exit